{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the first post - Titanic 001 ##\n",
    "#### Exploratory Data Analysis (EDA) ####\n",
    "\n",
    "This is an incredibly important part of any data analysis project. Perhaps understandably, it is also often overlooked - it appears not to get us any closer to a model or solution and can be incredibly time consuming. But time spent here will make our our models much better and our future selves much happier! (After writing this first post I have realised we do very little of this at all, fear not, we will in future posts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import various libraries, don't worry if you have not met all of these before (particularly all of the sklearn classifiers) we will explain them all later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning (sort of!)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done any data science before, the following will be familiar. Given the dataset is not vast, we can just read in using the pd.read_csv() function. There are some cool and far more performant ways of reading large datasets into pandas which we might explore later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ce3d7_\">\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th class=\"blank level0\">\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col0\">\n",
       "    PassengerId\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col1\">\n",
       "    Survived\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col2\">\n",
       "    Pclass\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col3\">\n",
       "    Name\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col4\">\n",
       "    Sex\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col5\">\n",
       "    Age\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col6\">\n",
       "    SibSp\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col7\">\n",
       "    Parch\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col8\">\n",
       "    Ticket\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col9\">\n",
       "    Fare\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col10\">\n",
       "    Cabin\n",
       "   </th>\n",
       "   <th class=\"col_heading level0 col11\">\n",
       "    Embarked\n",
       "   </th>\n",
       "  </tr>\n",
       " </thead>\n",
       " <tbody>\n",
       "  <tr>\n",
       "   <th class=\"row_heading level0 row0\" id=\"T_ce3d7_level0_row0\">\n",
       "    0\n",
       "   </th>\n",
       "   <td class=\"data row0 col0\" id=\"T_ce3d7_row0_col0\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row0 col1\" id=\"T_ce3d7_row0_col1\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row0 col2\" id=\"T_ce3d7_row0_col2\">\n",
       "    3\n",
       "   </td>\n",
       "   <td class=\"data row0 col3\" id=\"T_ce3d7_row0_col3\">\n",
       "    Braund, Mr. Owen Harris\n",
       "   </td>\n",
       "   <td class=\"data row0 col4\" id=\"T_ce3d7_row0_col4\">\n",
       "    male\n",
       "   </td>\n",
       "   <td class=\"data row0 col5\" id=\"T_ce3d7_row0_col5\">\n",
       "    22.000000\n",
       "   </td>\n",
       "   <td class=\"data row0 col6\" id=\"T_ce3d7_row0_col6\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row0 col7\" id=\"T_ce3d7_row0_col7\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row0 col8\" id=\"T_ce3d7_row0_col8\">\n",
       "    A/5 21171\n",
       "   </td>\n",
       "   <td class=\"data row0 col9\" id=\"T_ce3d7_row0_col9\">\n",
       "    7.250000\n",
       "   </td>\n",
       "   <td class=\"data row0 col10\" id=\"T_ce3d7_row0_col10\">\n",
       "    nan\n",
       "   </td>\n",
       "   <td class=\"data row0 col11\" id=\"T_ce3d7_row0_col11\">\n",
       "    S\n",
       "   </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <th class=\"row_heading level0 row1\" id=\"T_ce3d7_level0_row1\">\n",
       "    1\n",
       "   </th>\n",
       "   <td class=\"data row1 col0\" id=\"T_ce3d7_row1_col0\">\n",
       "    2\n",
       "   </td>\n",
       "   <td class=\"data row1 col1\" id=\"T_ce3d7_row1_col1\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row1 col2\" id=\"T_ce3d7_row1_col2\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row1 col3\" id=\"T_ce3d7_row1_col3\">\n",
       "    Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
       "   </td>\n",
       "   <td class=\"data row1 col4\" id=\"T_ce3d7_row1_col4\">\n",
       "    female\n",
       "   </td>\n",
       "   <td class=\"data row1 col5\" id=\"T_ce3d7_row1_col5\">\n",
       "    38.000000\n",
       "   </td>\n",
       "   <td class=\"data row1 col6\" id=\"T_ce3d7_row1_col6\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row1 col7\" id=\"T_ce3d7_row1_col7\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row1 col8\" id=\"T_ce3d7_row1_col8\">\n",
       "    PC 17599\n",
       "   </td>\n",
       "   <td class=\"data row1 col9\" id=\"T_ce3d7_row1_col9\">\n",
       "    71.283300\n",
       "   </td>\n",
       "   <td class=\"data row1 col10\" id=\"T_ce3d7_row1_col10\">\n",
       "    C85\n",
       "   </td>\n",
       "   <td class=\"data row1 col11\" id=\"T_ce3d7_row1_col11\">\n",
       "    C\n",
       "   </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <th class=\"row_heading level0 row2\" id=\"T_ce3d7_level0_row2\">\n",
       "    2\n",
       "   </th>\n",
       "   <td class=\"data row2 col0\" id=\"T_ce3d7_row2_col0\">\n",
       "    3\n",
       "   </td>\n",
       "   <td class=\"data row2 col1\" id=\"T_ce3d7_row2_col1\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row2 col2\" id=\"T_ce3d7_row2_col2\">\n",
       "    3\n",
       "   </td>\n",
       "   <td class=\"data row2 col3\" id=\"T_ce3d7_row2_col3\">\n",
       "    Heikkinen, Miss. Laina\n",
       "   </td>\n",
       "   <td class=\"data row2 col4\" id=\"T_ce3d7_row2_col4\">\n",
       "    female\n",
       "   </td>\n",
       "   <td class=\"data row2 col5\" id=\"T_ce3d7_row2_col5\">\n",
       "    26.000000\n",
       "   </td>\n",
       "   <td class=\"data row2 col6\" id=\"T_ce3d7_row2_col6\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row2 col7\" id=\"T_ce3d7_row2_col7\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row2 col8\" id=\"T_ce3d7_row2_col8\">\n",
       "    STON/O2. 3101282\n",
       "   </td>\n",
       "   <td class=\"data row2 col9\" id=\"T_ce3d7_row2_col9\">\n",
       "    7.925000\n",
       "   </td>\n",
       "   <td class=\"data row2 col10\" id=\"T_ce3d7_row2_col10\">\n",
       "    nan\n",
       "   </td>\n",
       "   <td class=\"data row2 col11\" id=\"T_ce3d7_row2_col11\">\n",
       "    S\n",
       "   </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <th class=\"row_heading level0 row3\" id=\"T_ce3d7_level0_row3\">\n",
       "    3\n",
       "   </th>\n",
       "   <td class=\"data row3 col0\" id=\"T_ce3d7_row3_col0\">\n",
       "    4\n",
       "   </td>\n",
       "   <td class=\"data row3 col1\" id=\"T_ce3d7_row3_col1\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row3 col2\" id=\"T_ce3d7_row3_col2\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row3 col3\" id=\"T_ce3d7_row3_col3\">\n",
       "    Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
       "   </td>\n",
       "   <td class=\"data row3 col4\" id=\"T_ce3d7_row3_col4\">\n",
       "    female\n",
       "   </td>\n",
       "   <td class=\"data row3 col5\" id=\"T_ce3d7_row3_col5\">\n",
       "    35.000000\n",
       "   </td>\n",
       "   <td class=\"data row3 col6\" id=\"T_ce3d7_row3_col6\">\n",
       "    1\n",
       "   </td>\n",
       "   <td class=\"data row3 col7\" id=\"T_ce3d7_row3_col7\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row3 col8\" id=\"T_ce3d7_row3_col8\">\n",
       "    113803\n",
       "   </td>\n",
       "   <td class=\"data row3 col9\" id=\"T_ce3d7_row3_col9\">\n",
       "    53.100000\n",
       "   </td>\n",
       "   <td class=\"data row3 col10\" id=\"T_ce3d7_row3_col10\">\n",
       "    C123\n",
       "   </td>\n",
       "   <td class=\"data row3 col11\" id=\"T_ce3d7_row3_col11\">\n",
       "    S\n",
       "   </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <th class=\"row_heading level0 row4\" id=\"T_ce3d7_level0_row4\">\n",
       "    4\n",
       "   </th>\n",
       "   <td class=\"data row4 col0\" id=\"T_ce3d7_row4_col0\">\n",
       "    5\n",
       "   </td>\n",
       "   <td class=\"data row4 col1\" id=\"T_ce3d7_row4_col1\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row4 col2\" id=\"T_ce3d7_row4_col2\">\n",
       "    3\n",
       "   </td>\n",
       "   <td class=\"data row4 col3\" id=\"T_ce3d7_row4_col3\">\n",
       "    Allen, Mr. William Henry\n",
       "   </td>\n",
       "   <td class=\"data row4 col4\" id=\"T_ce3d7_row4_col4\">\n",
       "    male\n",
       "   </td>\n",
       "   <td class=\"data row4 col5\" id=\"T_ce3d7_row4_col5\">\n",
       "    35.000000\n",
       "   </td>\n",
       "   <td class=\"data row4 col6\" id=\"T_ce3d7_row4_col6\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row4 col7\" id=\"T_ce3d7_row4_col7\">\n",
       "    0\n",
       "   </td>\n",
       "   <td class=\"data row4 col8\" id=\"T_ce3d7_row4_col8\">\n",
       "    373450\n",
       "   </td>\n",
       "   <td class=\"data row4 col9\" id=\"T_ce3d7_row4_col9\">\n",
       "    8.050000\n",
       "   </td>\n",
       "   <td class=\"data row4 col10\" id=\"T_ce3d7_row4_col10\">\n",
       "    nan\n",
       "   </td>\n",
       "   <td class=\"data row4 col11\" id=\"T_ce3d7_row4_col11\">\n",
       "    S\n",
       "   </td>\n",
       "  </tr>\n",
       " </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.head()\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the head of the DF to check there is nothing too funky going on. We can already see some categorical data (numeric: \"Survived\" and string: \"Sex\"). The other thing to note is that \"Cabin\" has some NaN values that we will have to deal with later! We will use \"Sex\" now so let's make the catergorical data to a dummy variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['SexDummy'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at some basic information of the pandas DataFrame using the .info() method. One thing that we should pay particular attention to is the count of variables. There is non-complete data for \"Cabin\", \"Age\" and \"Embarked\" although the latter is only missing 2 data points so we won't lose too much sleep over that. Cabin we will probably not end up using either. From the head of the DataFrame above it doens't look like that will convey much useful information. The missing values in \"Age\" are a bit more worrying. We will explore methods to impute the missing values from a passenger's other data in a later post, for now however, we will ingore \"Age\".   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passenger Class and Sex\n",
    "\n",
    "This will be a very simple model using only these two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the survival rate for these various groups (Sex and Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(10, 240, as_cmap=True)\n",
    "sns.set(rc={'figure.figsize':(14.7,8.27)})\n",
    "\n",
    "\n",
    "df = train_df.pivot_table(index='Sex', columns='Pclass', values='Survived', aggfunc=np.mean)\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df, cmap=cmap, annot=True, ax=ax)\n",
    "ax.set_title(\"Survival Rate by Passenger Sex and Class\", pad=20)\n",
    "ax.set(xlabel='Passenger Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So who is most likely to survive? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well if you were female and you were in first class (Passenger Class = 1), you had a 97% chance of survival. If you were a male in third class things aren't looking too rosy, this drops all the way down to 14% - quite a remarkable difference. Whilst \"Passenger Class\" looks to be a very important predictor, you can see that a female, even in third class, was much more likely to survive than any male."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Logistic Regression Model\n",
    "\n",
    "If you are not familar with Logistic Regression there is an earlier post on what it is and why we use it. There are some very good reasons not to use more traditional regression methods like OLS in classification problems like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Sklearn's test_train_split() to split the dataset into two sections, one that we will use for training our model and one we will use for testing or validating our model. We have split the data using a ration of 1:3 our test dataset is half as big as our train dataset.\n",
    "\n",
    "Next we instatiate the Logistic Regression model and fit it to our newly created training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df[[\"Pclass\",\"SexDummy\"]], train_df[\"Survived\"], test_size=0.33, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, y_train) * 100, 2)\n",
    "cf_matrix = confusion_matrix(Y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices are a nice way to visualise the performance of your classifier. Most passengers were classified correctly (~78% of them). We had slightly more false positives - 36 passengers - than false negatives - 24 passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(cf_matrix, annot=True, cmap=cmap, fmt=\"g\", ax=ax)\n",
    "ax.set_title(\"Confusion Matrix of Predicitons\", pad=20)\n",
    "ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['survived', 'died']); ax.yaxis.set_ticklabels(['survived', 'died'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model Accuracy: {acc_log}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll leave this post here for now and will improve our model later. It's surprising quite how well our model was able to predict survival given only two, very basic descriptor variables. In future posts we will look at extracting hidden data from some variables, imputing missing data and playing around with various models/ensemble techniques. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
